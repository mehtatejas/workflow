## Title

**Implement Full Requirement Lifecycle: Creation, Approval, Advance & Result Submission**

---

## Tech Stack

* **Package Management**: Poetry
* **Language & Runtime**: Python 3.11.8
* **Web Server**: Uvicorn
* **Web Framework**: FastAPI
* **Schema & Validation**: Pydantic 2.0
* **ORM / Database Models**: SQLModel
* **Database**: SQLite
* **LLM Invocation**: LangChain wrapper for Azure OpenAI
* **Test Doubles**: Mock JSON stubs for Azure responses
* **CI / Quality**: Black, Flake8, Pytest

---

## Description

This service implements a four-step lifecycle for handling “Requirements” through a sequence of predefined “ProcessMaster” tasks, each executed via an Azure OpenAI call. Every interaction is exposed over HTTP with FastAPI and persisted in SQLite using SQLModel, complete with audit fields (`created_by`, `created_at`, `updated_by`, `updated_at`) on all tables.

1. **Create Requirement (`POST /requirements/`)**

   * Accepts free-form text.
   * Stores it immediately as a new record in the `Requirement` table with `status = new`.

2. **Approve Requirement (`PUT /requirements/{id}/approve`)**

   * Allows updating both the requirement’s text (e.g. clarifications) and setting its business priority (P1–P5).
   * Moves the `Requirement` from `new` → `approved`, enabling it to enter the processing pipeline.

3. **Advance Workflow Step (`POST /requirements/{id}/advance`)**

   * Synchronously triggers the next incomplete step in the pipeline.
   * **Prompt assembly**:

     1. Load the next `ProcessMaster` record by `process_order`.
     2. Concatenate its `process_prompt` with the current `Requirement.text`.
     3. Append a “History” section listing all prior `Workflow.process_result` entries in their original order.
   * **LLM call**: Pass the assembled prompt to Azure OpenAI via your LangChain wrapper.
   * **Persistence**: Create a new `Workflow` entry with `prompt`, the returned `process_result`, and `status = new`.

4. **Submit Workflow Result (`PUT /workflows/{workflow_id}`)**

   * Finalizes a `Workflow` entry: updates its `process_result` and marks it `complete` or `failed`.
   * If it was the last step in the `ProcessMaster` sequence for that requirement, automatically updates the parent `Requirement.status` to `done`.

Every endpoint uses Pydantic schemas for strict request/response validation and appears in the autogenerated OpenAPI UI. The synchronous design of the “advance” step guarantees that prompts and results live together in a single transaction, simplifying downstream auditing and retries.

**Error handling**

* 404s for missing or improperly-stateful resources (e.g. advancing an unapproved requirement).
* 400s for invalid transitions (e.g. no steps remain).

**Testing & CI**

* **Pytest** + FastAPI’s TestClient exercise all happy- and sad-paths.
* LangChain/Azure calls are monkey-patched to return fixed JSON stubs.
* Black + Flake8 enforce code style, with CI gating on ≥100% coverage for all new modules.

---

## 1. Data Models

```python
from uuid import UUID, uuid4
from datetime import datetime
from typing import Literal, Optional
from sqlmodel import SQLModel, Field

class ProcessMaster(SQLModel, table=True):
    id: UUID = Field(default_factory=uuid4, primary_key=True)
    type: str
    description: str
    process_prompt: str
    analysis_prompt: str
    process_order: int
    created_by: str
    created_at: datetime
    updated_by: str
    updated_at: datetime

class Requirement(SQLModel, table=True):
    id: UUID = Field(default_factory=uuid4, primary_key=True)
    text: str
    priority: Optional[Literal["P1","P2","P3","P4","P5"]] = None
    status: Literal["new","approved","rejected","done"] = "new"
    created_by: str
    created_at: datetime
    updated_by: str
    updated_at: datetime

class Workflow(SQLModel, table=True):
    id: UUID = Field(default_factory=uuid4, primary_key=True)
    requirement_id: UUID = Field(foreign_key="requirement.id")
    process_id: UUID = Field(foreign_key="processmaster.id")
    prompt: str
    process_result: Optional[str] = None
    status: Literal["new","complete","failed"] = "new"
    created_by: str
    created_at: datetime
    updated_by: str
    updated_at: datetime
```

---

## 2. Endpoints

### 2.1 Create Requirement

* **`POST /requirements/`**
* **Body**:

  ```json
  {
    "text": "Describe your requirement"
  }
  ```
* **Action**:

  * Validate input, insert a `Requirement` with `status="new"`.
* **Response**:

  * `201 Created` + full `Requirement` JSON

---

### 2.2 Approve Requirement

* **`PUT /requirements/{requirement_id}/approve`**
* **Body**:

  ```json
  {
    "text": "Updated your requirement",
    "priority": "P1"
  }
  ```
* **Action**:

  1. Verify `Requirement` exists and has `status="new"`.
  2. Update its `text`, set `status="approved"`, and set `priority`.
* **Response**:

  * `200 OK` + updated `Requirement` JSON
* **Errors**:

  * `404 Not Found` if missing or not `new`.

---

### 2.3 Advance Workflow Step

* **`POST /requirements/{requirement_id}/advance`**
* **Action**:

  1. Verify `Requirement` exists and has `status="approved"`.
  2. Select the next `ProcessMaster` step: lowest `process_order` with **no** existing `Workflow`.
  3. **Assemble** the prompt string by concatenating in order:

     * `ProcessMaster.process_prompt`
     * `Requirement.text`
     * **History**: a bullet list of all prior `Workflow.process_result` entries.
  4. **Invoke** Azure OpenAI via LangChain with that prompt.
  5. **Insert** a new `Workflow` record with:

     * `requirement_id`
     * `process_id`
     * `prompt`
     * `process_result` (LLM response)
     * `status="new"`
     * audit fields
* **Response**:

  * `201 Created`

    ```json
    {
      "workflow_id": "<new UUID>",
      "prompt": "<assembled prompt>",
      "process_result": "<LLM response>"
    }
    ```
* **Errors**:

  * `404 Not Found` if the requirement is missing or not `approved`.
  * `400 Bad Request` if no steps remain.

---

### 2.4 Submit Workflow Result

* **`PUT /workflows/{workflow_id}`**
* **Body**:

  ```json
  {
    "process_result": "LLM response here",
    "status": "complete"  // or "failed"
  }
  ```
* **Action**:

  1. Verify `Workflow` exists and has `status="new"`.
  2. Update its `process_result`, `status`, and audit fields.
  3. If `status="complete"` **and** this was the last step for the requirement, set `Requirement.status="done"`.
* **Response**:

  * `200 OK` + updated `Workflow` JSON
* **Errors**:

  * `404 Not Found` if missing or not `new`.
  * `400 Bad Request` for invalid status.

---

## 3. Acceptance Criteria

* **Models**: All three tables exist with correct fields, types, FKs, and audit columns.
* **POST /requirements/**: Validates input, creates `new` Requirement, returns `201`.
* **PUT /requirements/{id}/approve**: Only moves `new` → `approved`, updates text & priority, returns `200`.
* **POST /requirements/{id}/advance**:

  * Picks the next step by `process_order`.
  * Assembles prompt including history bullets.
  * Invokes Azure OpenAI.
  * Inserts `Workflow` row with `prompt`, `process_result`, `status="new"`.
  * Returns `201` with `workflow_id`, `prompt`, and `process_result`.
* **PUT /workflows/{id}**:

  * Only updates `status="new"` rows.
  * Persists `process_result` & `status`.
  * Marks Requirement `done` after final step.
  * Returns `200` with updated record.
* **Testing**:

  * Pytest covers all four endpoints (happy & error paths via TestClient).
  * Unit tests for prompt-assembly and final-step completion.
  * LangChain/Azure calls mocked via JSON stubs.
* **Code Quality**: Passes Black & Flake8; CI enforces ≥100% coverage on new modules.
* **Documentation**: Pydantic schemas with examples in docstrings; OpenAPI UI shows models & examples; README updated with mock vs. real Azure credentials instructions.
